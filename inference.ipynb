{"cells":[{"cell_type":"markdown","metadata":{"id":"8ovkjgjGIC4Y"},"source":["# Review Classification Inference\n","\n","Use trained Longformer model to classify reviews from 2021, 2022, 2023.\n","\n","- Model: Fine-tuned Longformer\n","- Task: Binary classification (Real reviews vs AI-generated reviews)\n","- Data: ICLR 2021, 2022, 2023 review data\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCLYKUQHIC4c","executionInfo":{"status":"ok","timestamp":1762401389767,"user_tz":300,"elapsed":41592,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"7e346875-b31f-4779-ed34-3b8f3878e670"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Collecting datasets\n","  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Collecting pyarrow>=21.0.0 (from datasets)\n","  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyarrow, pandas, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 18.1.0\n","    Uninstalling pyarrow-18.1.0:\n","      Successfully uninstalled pyarrow-18.1.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n","pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n","cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-4.4.1 pandas-2.3.3 pyarrow-22.0.0\n","Mounted at /content/drive\n"]}],"source":["%pip install transformers datasets accelerate peft pandas tqdm -U\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyg7GU-9IC4d","executionInfo":{"status":"ok","timestamp":1762401409533,"user_tz":300,"elapsed":19761,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"9cb916b6-2a8f-40e8-f3ae-a73c278b64cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.8.0+cu126\n","CUDA available: True\n","GPU: NVIDIA L4\n"]}],"source":["import torch\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","import pandas as pd\n","import torch\n","from transformers import LongformerTokenizer, LongformerForSequenceClassification\n","from peft import PeftModel\n","from tqdm import tqdm\n","import os\n","from datetime import datetime\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEQ92R9KIC4e","executionInfo":{"status":"ok","timestamp":1762401409545,"user_tz":300,"elapsed":8,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"58e37d24-3a7a-4dd4-eb0e-44919c21fbaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","Review Classification Inference Script (LoRA Model)\n","============================================================\n","Base model: allenai/longformer-base-4096\n","LoRA adapter path: /content/drive/MyDrive/Notebooks/AI_review/finetuned_longformer_lora1\n","Max length: 2048\n","Batch size: 8\n","Output directory: ./inference_results\n","============================================================\n"]}],"source":["# Path to the trained LoRA model (modify as needed)\n","MODEL_PATH = '/content/drive/MyDrive/Notebooks/AI_review/finetuned_longformer_lora1'  # Change this to your LoRA model path\n","BASE_MODEL_NAME = 'allenai/longformer-base-4096'  # Base model name\n","\n","# Model configuration\n","MAX_LENGTH = 2048\n","BATCH_SIZE = 8\n","\n","# Data paths\n","DATA_PATHS = {\n","    '2021': '/content/drive/MyDrive/Notebooks/AI_review/iclr_2021_data/iclr_2021_reviews.csv',\n","    '2022': '/content/drive/MyDrive/Notebooks/AI_review/iclr_2022_data/iclr_2022_reviews.csv',\n","    '2023': '/content/drive/MyDrive/Notebooks/AI_review/iclr_2023_data/iclr_2023_reviews.csv',\n","}\n","\n","# Output path\n","OUTPUT_DIR = './inference_results'\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","print(\"=\"*60)\n","print(\"Review Classification Inference Script (LoRA Model)\")\n","print(\"=\"*60)\n","print(f\"Base model: {BASE_MODEL_NAME}\")\n","print(f\"LoRA adapter path: {MODEL_PATH}\")\n","print(f\"Max length: {MAX_LENGTH}\")\n","print(f\"Batch size: {BATCH_SIZE}\")\n","print(f\"Output directory: {OUTPUT_DIR}\")\n","print(\"=\"*60)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"g3F3MhfYIC4e","executionInfo":{"status":"ok","timestamp":1762401409562,"user_tz":300,"elapsed":14,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}}},"outputs":[],"source":["def load_model_and_tokenizer(lora_model_path, base_model_name):\n","    \"\"\"Load LoRA fine-tuned model and tokenizer\"\"\"\n","    print(f\"\\nLoading LoRA model from: {lora_model_path}\")\n","    print(f\"Base model: {base_model_name}\")\n","\n","    # Detect device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using device: {device}\")\n","\n","    # Load tokenizer from LoRA model path\n","    print(\"\\nLoading tokenizer...\")\n","    tokenizer = LongformerTokenizer.from_pretrained(lora_model_path)\n","\n","    # Load base model first\n","    print(\"Loading base model...\")\n","    base_model = LongformerForSequenceClassification.from_pretrained(\n","        base_model_name,\n","        num_labels=2\n","    )\n","\n","    # Load LoRA adapter\n","    print(\"Loading LoRA adapter...\")\n","    model = PeftModel.from_pretrained(base_model, lora_model_path)\n","\n","    # Move to device and set to eval mode\n","    model.to(device)\n","    model.eval()\n","\n","    print(\"✓ LoRA model loaded successfully!\")\n","    return model, tokenizer, device\n","\n","\n","def load_reviews_from_csv(csv_path):\n","    \"\"\"Load review data from CSV file\"\"\"\n","    print(f\"\\nLoading data: {csv_path}\")\n","\n","    if not os.path.exists(csv_path):\n","        print(f\"File does not exist, skipping: {csv_path}\")\n","        return None\n","\n","    df = pd.read_csv(csv_path)\n","\n","    # Filter empty reviews\n","    df = df[df['review_text'].notna()]\n","    df = df[df['review_text'].str.strip().str.len() > 0]\n","\n","    print(f\"  ✓ Loaded {len(df)} valid reviews\")\n","    return df\n","\n","\n","def predict_reviews(model, tokenizer, device, reviews, batch_size=8, max_length=2048):\n","    \"\"\"Batch prediction for review list\"\"\"\n","    predictions = []\n","    probabilities = []\n","\n","    print(f\"\\nStarting inference on {len(reviews)} reviews...\")\n","\n","    with torch.no_grad():\n","        # Process in batches\n","        for i in tqdm(range(0, len(reviews), batch_size), desc=\"Inference progress\"):\n","            batch_texts = reviews[i:i + batch_size]\n","\n","            # Tokenize\n","            inputs = tokenizer(\n","                batch_texts,\n","                return_tensors='pt',\n","                truncation=True,\n","                padding=True,\n","                max_length=max_length\n","            )\n","\n","            # Move to device\n","            inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","            # Predict\n","            outputs = model(**inputs)\n","            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","            preds = torch.argmax(probs, dim=-1)\n","\n","            # Save results\n","            predictions.extend(preds.cpu().numpy().tolist())\n","            probabilities.extend(probs.cpu().numpy().tolist())\n","\n","    return predictions, probabilities\n","\n","\n","def process_year_data(year, csv_path, model, tokenizer, device):\n","    \"\"\"Process data for a specific year\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"Processing {year} data\")\n","    print(\"=\"*60)\n","\n","    # Load data\n","    df = load_reviews_from_csv(csv_path)\n","    if df is None:\n","        return None\n","\n","    # Extract review texts\n","    reviews = df['review_text'].astype(str).tolist()\n","\n","    # Make predictions\n","    predictions, probabilities = predict_reviews(\n","        model, tokenizer, device, reviews,\n","        batch_size=BATCH_SIZE,\n","        max_length=MAX_LENGTH\n","    )\n","\n","    # Add prediction results to DataFrame\n","    df['predicted_label'] = predictions\n","    df['predicted_class'] = ['AI-generated' if p == 1 else 'Real' for p in predictions]\n","    df['prob_real'] = [prob[0] for prob in probabilities]\n","    df['prob_ai'] = [prob[1] for prob in probabilities]\n","\n","    # Statistics\n","    real_count = predictions.count(0)\n","    ai_count = predictions.count(1)\n","\n","    print(\"\\nPrediction statistics:\")\n","    print(f\"  Real reviews (label 0): {real_count} ({real_count/len(predictions)*100:.1f}%)\")\n","    print(f\"  AI-generated (label 1): {ai_count} ({ai_count/len(predictions)*100:.1f}%)\")\n","\n","    return df\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437,"referenced_widgets":["2c1a7f23023146df92250b886fd88085","8f7fb48dfc7b471eacb2c363329df0d1","b93167ccb36a45148abb370d23a356f5","62e485cdbdf4448692949c8260cc0782","c056d93e55254165862583dd343de7ef","7354d6de613b4f9ebced32a8e82864bb","d119486f28664e6f9d98689da9a1c06c","f7e57e936f3e4359a0b13d19c1954279","329b8619574d4cd7a0fcef5da7b7a70d","6704aebbe36743a7aed8eedf54fa836d","49d24e509ca3492dbf922fa307755c41","361954c5ea4441519ec4b874289672a9","ec4da626c3ef4fb995008c23ddc4d827","2ab4a450c724406a99dcd625aaa82504","65ec0d49c27f4785842a4c4a93399190","6a8c74c990fd4ba1aac94d3d3af9e7d3","2e084df665744de5b72ab91e23345644","e15e79df6cf24acc9c4a1946feab5a1d","39a8e19f16654d17883432ba598a2905","a1ca737ef068466db39938153f74434e","227630c4a1ba4098974a59adef5d166e","95add73cbd8b4c0299c2b2c379d24242","6e45e6b313634eeca377f72f3bf48490","fcd6be5d605046dda6283d45651626db","59486c8e538145a7a2f221ea8b992852","3fcc596054cc4586a06c7f441d5cbe6e","f72edf286fcf4f949a8feae3ef86216b","f89b1ea9cfd84fac9a06f06ce2b0c24e","69f4750cb01c4b2996d05154579ef88e","72956e2df2344e21a33b59e50e9be3de","d686f0716c4b4edaa7ff4cfd55e86672","12a6ae273644441fa28a7bf17f55c4a8","0805cda9a8ff4c64b45d7555a4a95e6a"]},"id":"_nLG4qC3IC4f","executionInfo":{"status":"ok","timestamp":1762401424480,"user_tz":300,"elapsed":14917,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"a00b4c24-a285-4eb7-edde-db5a15cd9d17"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loading LoRA model from: /content/drive/MyDrive/Notebooks/AI_review/finetuned_longformer_lora1\n","Base model: allenai/longformer-base-4096\n","Using device: cuda\n","\n","Loading tokenizer...\n","Loading base model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1a7f23023146df92250b886fd88085"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"361954c5ea4441519ec4b874289672a9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loading LoRA adapter...\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/597M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e45e6b313634eeca377f72f3bf48490"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ LoRA model loaded successfully!\n"]}],"source":["model, tokenizer, device = load_model_and_tokenizer(MODEL_PATH, BASE_MODEL_NAME)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6UJ6IioIC4f","executionInfo":{"status":"ok","timestamp":1762401587360,"user_tz":300,"elapsed":162877,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"905cc12b-01a0-4582-fc3b-6d3d762d5125"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Processing 2021 data\n","============================================================\n","\n","Loading data: /content/drive/MyDrive/Notebooks/AI_review/iclr_2021_data/iclr_2021_reviews.csv\n","  ✓ Loaded 388 valid reviews\n","\n","Starting inference on 388 reviews...\n"]},{"output_type":"stream","name":"stderr","text":["\rInference progress:   0%|          | 0/49 [00:00<?, ?it/s]Initializing global attention on CLS token...\n","Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n","Inference progress: 100%|██████████| 49/49 [01:02<00:00,  1.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction statistics:\n","  Real reviews (label 0): 124 (32.0%)\n","  AI-generated (label 1): 264 (68.0%)\n","\n","============================================================\n","Processing 2022 data\n","============================================================\n","\n","Loading data: /content/drive/MyDrive/Notebooks/AI_review/iclr_2022_data/iclr_2022_reviews.csv\n","  ✓ Loaded 386 valid reviews\n","\n","Starting inference on 386 reviews...\n"]},{"output_type":"stream","name":"stderr","text":["Inference progress: 100%|██████████| 49/49 [00:55<00:00,  1.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction statistics:\n","  Real reviews (label 0): 206 (53.4%)\n","  AI-generated (label 1): 180 (46.6%)\n","\n","============================================================\n","Processing 2023 data\n","============================================================\n","\n","Loading data: /content/drive/MyDrive/Notebooks/AI_review/iclr_2023_data/iclr_2023_reviews.csv\n","  ✓ Loaded 378 valid reviews\n","\n","Starting inference on 378 reviews...\n"]},{"output_type":"stream","name":"stderr","text":["Inference progress: 100%|██████████| 48/48 [00:40<00:00,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction statistics:\n","  Real reviews (label 0): 276 (73.0%)\n","  AI-generated (label 1): 102 (27.0%)\n","\n","Processed 3 years of data successfully!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["all_results = {}\n","\n","for year, csv_path in DATA_PATHS.items():\n","    result_df = process_year_data(year, csv_path, model, tokenizer, device)\n","    if result_df is not None:\n","        all_results[year] = result_df\n","\n","print(f\"\\nProcessed {len(all_results)} years of data successfully!\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s3_SIzLIC4f","executionInfo":{"status":"ok","timestamp":1762401587449,"user_tz":300,"elapsed":75,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"83d466d2-9ddd-4d4e-fb98-d48c91cfe35b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Saving inference results\n","============================================================\n","✓ 2021 results saved: ./inference_results/inference_results_2021_20251106_035947.csv\n","✓ 2022 results saved: ./inference_results/inference_results_2022_20251106_035947.csv\n","✓ 2023 results saved: ./inference_results/inference_results_2023_20251106_035947.csv\n","\n","All results saved successfully!\n"]}],"source":["print(\"\\n\" + \"=\"*60)\n","print(\"Saving inference results\")\n","print(\"=\"*60)\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","for year, df in all_results.items():\n","    # Save full results\n","    output_path = os.path.join(OUTPUT_DIR, f'inference_results_{year}_{timestamp}.csv')\n","    df.to_csv(output_path, index=False)\n","    print(f\"✓ {year} results saved: {output_path}\")\n","\n","    # Save summary statistics\n","    summary = {\n","        'year': year,\n","        'total': len(df),\n","        'real_count': (df['predicted_label'] == 0).sum(),\n","        'ai_count': (df['predicted_label'] == 1).sum(),\n","        'real_percentage': f\"{(df['predicted_label'] == 0).sum() / len(df) * 100:.2f}%\",\n","        'ai_percentage': f\"{(df['predicted_label'] == 1).sum() / len(df) * 100:.2f}%\",\n","    }\n","\n","    # Save summary to separate file\n","    summary_df = pd.DataFrame([summary])\n","    summary_path = os.path.join(OUTPUT_DIR, f'summary_{year}_{timestamp}.csv')\n","    summary_df.to_csv(summary_path, index=False)\n","\n","print(\"\\nAll results saved successfully!\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7dOMyEYIC4g","executionInfo":{"status":"ok","timestamp":1762401587472,"user_tz":300,"elapsed":17,"user":{"displayName":"Siyuan Shen","userId":"09436717134049659854"}},"outputId":"2c2b0d8a-009d-41eb-c7e4-1f471180d8aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Overall Summary Statistics\n","============================================================\n","\n","year  total  ai_count ai_percentage\n","2021    388       264        68.04%\n","2022    386       180        46.63%\n","2023    378       102        26.98%\n","\n","✓ Overall summary saved: ./inference_results/overall_summary_20251106_035947.csv\n"]}],"source":["# Overall Summary - AI percentage for each year\n","if all_results:\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Overall Summary Statistics\")\n","    print(\"=\"*60)\n","\n","    summary_data = []\n","    for year, df in all_results.items():\n","        ai_percentage = (df['predicted_label'] == 1).sum() / len(df) * 100\n","        summary_data.append({\n","            'year': year,\n","            'total': len(df),\n","            'ai_count': (df['predicted_label'] == 1).sum(),\n","            'ai_percentage': f\"{ai_percentage:.2f}%\",\n","        })\n","\n","    summary_df = pd.DataFrame(summary_data)\n","    overall_summary_path = os.path.join(OUTPUT_DIR, f'overall_summary_{timestamp}.csv')\n","    summary_df.to_csv(overall_summary_path, index=False)\n","\n","    print(\"\\n\" + summary_df.to_string(index=False))\n","    print(f\"\\n✓ Overall summary saved: {overall_summary_path}\")\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2c1a7f23023146df92250b886fd88085":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f7fb48dfc7b471eacb2c363329df0d1","IPY_MODEL_b93167ccb36a45148abb370d23a356f5","IPY_MODEL_62e485cdbdf4448692949c8260cc0782"],"layout":"IPY_MODEL_c056d93e55254165862583dd343de7ef"}},"8f7fb48dfc7b471eacb2c363329df0d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7354d6de613b4f9ebced32a8e82864bb","placeholder":"​","style":"IPY_MODEL_d119486f28664e6f9d98689da9a1c06c","value":"config.json: 100%"}},"b93167ccb36a45148abb370d23a356f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7e57e936f3e4359a0b13d19c1954279","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_329b8619574d4cd7a0fcef5da7b7a70d","value":694}},"62e485cdbdf4448692949c8260cc0782":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6704aebbe36743a7aed8eedf54fa836d","placeholder":"​","style":"IPY_MODEL_49d24e509ca3492dbf922fa307755c41","value":" 694/694 [00:00&lt;00:00, 89.1kB/s]"}},"c056d93e55254165862583dd343de7ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7354d6de613b4f9ebced32a8e82864bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d119486f28664e6f9d98689da9a1c06c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7e57e936f3e4359a0b13d19c1954279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329b8619574d4cd7a0fcef5da7b7a70d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6704aebbe36743a7aed8eedf54fa836d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49d24e509ca3492dbf922fa307755c41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"361954c5ea4441519ec4b874289672a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec4da626c3ef4fb995008c23ddc4d827","IPY_MODEL_2ab4a450c724406a99dcd625aaa82504","IPY_MODEL_65ec0d49c27f4785842a4c4a93399190"],"layout":"IPY_MODEL_6a8c74c990fd4ba1aac94d3d3af9e7d3"}},"ec4da626c3ef4fb995008c23ddc4d827":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e084df665744de5b72ab91e23345644","placeholder":"​","style":"IPY_MODEL_e15e79df6cf24acc9c4a1946feab5a1d","value":"pytorch_model.bin: 100%"}},"2ab4a450c724406a99dcd625aaa82504":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a8e19f16654d17883432ba598a2905","max":597257159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1ca737ef068466db39938153f74434e","value":597257159}},"65ec0d49c27f4785842a4c4a93399190":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_227630c4a1ba4098974a59adef5d166e","placeholder":"​","style":"IPY_MODEL_95add73cbd8b4c0299c2b2c379d24242","value":" 597M/597M [00:03&lt;00:00, 385MB/s]"}},"6a8c74c990fd4ba1aac94d3d3af9e7d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e084df665744de5b72ab91e23345644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e15e79df6cf24acc9c4a1946feab5a1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39a8e19f16654d17883432ba598a2905":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1ca737ef068466db39938153f74434e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"227630c4a1ba4098974a59adef5d166e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95add73cbd8b4c0299c2b2c379d24242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e45e6b313634eeca377f72f3bf48490":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcd6be5d605046dda6283d45651626db","IPY_MODEL_59486c8e538145a7a2f221ea8b992852","IPY_MODEL_3fcc596054cc4586a06c7f441d5cbe6e"],"layout":"IPY_MODEL_f72edf286fcf4f949a8feae3ef86216b"}},"fcd6be5d605046dda6283d45651626db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f89b1ea9cfd84fac9a06f06ce2b0c24e","placeholder":"​","style":"IPY_MODEL_69f4750cb01c4b2996d05154579ef88e","value":"model.safetensors: 100%"}},"59486c8e538145a7a2f221ea8b992852":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72956e2df2344e21a33b59e50e9be3de","max":597241956,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d686f0716c4b4edaa7ff4cfd55e86672","value":597241956}},"3fcc596054cc4586a06c7f441d5cbe6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12a6ae273644441fa28a7bf17f55c4a8","placeholder":"​","style":"IPY_MODEL_0805cda9a8ff4c64b45d7555a4a95e6a","value":" 597M/597M [00:01&lt;00:00, 302MB/s]"}},"f72edf286fcf4f949a8feae3ef86216b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f89b1ea9cfd84fac9a06f06ce2b0c24e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f4750cb01c4b2996d05154579ef88e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72956e2df2344e21a33b59e50e9be3de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d686f0716c4b4edaa7ff4cfd55e86672":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12a6ae273644441fa28a7bf17f55c4a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0805cda9a8ff4c64b45d7555a4a95e6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}